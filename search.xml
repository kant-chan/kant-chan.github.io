<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[DSA-tree]]></title>
    <url>%2F2018%2F08%2F10%2FDSA-tree%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[python 多进程 multiprocess(2) -- 进程间通信]]></title>
    <url>%2F2018%2F05%2F17%2Fmultiprocess-python-2%2F</url>
    <content type="text"><![CDATA[reference Queue使用 Queue 对象可以实现进程间通信, Queue 对象是线程和进程安全的. 12345678910def f(q): time.sleep(2) q.put([42, None, 'hello'])if __name__ == '__main__': q = Queue() p = Process(target=f, args=(q,), name='f') p.start() print(q.get()) print('%s is alive: %s' % (p.name, p.is_alive())) p.join() 输出为:12[42, None, &apos;hello&apos;]f is alive: True PipePipe 对象返回的元组分别代表管道的两端, 管道默认是全双工, 两端都支持 send 和 recv 方法, 两个进程分别操作管道两端时不会有冲突, 两个进程对管道一端同时读写时可能会有冲突. 如果声明了 p = Pipe(duplex=False) 的单向管道, 则 p[0] 只负责接受消息, p[1] 只负责发送消息. 123456789def f(conn): conn.send([42, None, 'hello']) conn.close()if __name__ == '__main__': parent_conn, child_conn = Pipe() p = Process(target=f, args=(child_conn,)) p.start() print(parent_conn.recv()) p.join() 共享状态并发编程中, 应该尽量避免进程或线程间共享状态. 在多线程中, 共享资源可以使用全局变量或者传递参数. 在多进程中, 由于每个进程有自己独立的内存空间, 以上方法并不合适. 12345678910a = 0def func(): global a a += 1 print('a in child process:', a)if __name__ == "__main__": p = Process(target=func) p.start() p.join() print('a in parent process:', a) 输出为:12a in child process: 1a in parent process: 0 共享内存在进程间共享状态可以使用 multiprocessing.Value 和 multiprocessing.Array 这样特殊的共享内存对象. 1234567891011121314from multiprocessing import Process, Value, Arraydef func(n, a): n.value = 3.1415926 for i in range(len(a)): a[i] = -iif __name__ == "__main__": # 'd'表示浮点型数据 'i'表示整数 n = Value('d', 0.0) a = Array('i', range(10)) p = Process(target=func, args=(n, a,)) p.start() p.join() print n.value print a[:] 服务进程multiprocessing.Manager 对象像是一个保存状态的代理, 其他进程通过与代理的接口通信取得状态信息, 服务进程支持更多的数据类型, 使用起来比共享内存更灵活. 12345678910111213141516from multiprocessing import Process, Managerdef func(d, l): d['1'] = 2 d[2] = 'str' d[3.0] = None for i in range(len(l)): l[i] = -iif __name__ == "__main__": m = Manager() l = m.list(range(10)) d = m.dict() p = Process(target=func, args=(d, l,)) p.start() p.join() print d print l 进程池针对任务量巨大的场景, 可以将进程放入进程池中, 每个进程可以看做是一个 worker. Pool 类可以提供指定数量的进程供用户调用, 当有新的请求提交到Pool中时, 如果池还没有满, 就会创建一个新的进程来执行请求. 如果池满, 请求就会告知先等待, 直到池中有进程结束, 才会创建新的进程来执行这些请求. multiprocessing.cpu_count() 可获得 cpu 核数 apply_async()apply_async(func[, args=()[, kwds={}[, callback=None]]]) close()关闭进程池 (pool), 使其不在接受新的任务. terminate()结束工作进程, 不在处理未处理的任务. join()主进程阻塞等待子进程的退出, join 方法必须在 close 或 terminate 之后使用. 示例1234567891011121314151617import multiprocessing as mpdef job(i): return i * iif __name__ == '__main__': results = [] # windows下加此句避免RuntimeError mp.freeze_support() pool = mp.Pool() for i in range(4): # pool.apply_async 采用异步方式调用 job result = pool.apply_async(job, args=(i, )) results.append(result) # 回收进程池 pool.close() pool.join() for res in results: print(res.get()) 上例中 res.get() 会等待上一个任务完成后再分配下一个任务, 是阻塞式的, 所以不将 print(res.get()) 放在 result = pool.apply_async(job, args=(i, )) 之后. 事实上, 获取返回值的过程最好放在进程池回收之后进行, 避免阻塞后面的语句. 1234567891011121314151617import multiprocessing as mpdef job(x): return x * xdef multicore(): # processes不提供默认使用全部的核 pool = mp.Pool(processes=mp.cpu_count()) res = pool.map(job, range(10)) print(res) res = pool.apply_async(job, (2,)) # 用get获得结果 print(res.get()) # 迭代器, i=0时apply一次, i=1时apply一次等等 multi_res = [pool.apply_async(job, (i,)) for i in range(10)] # 从迭代器中取出 print([res.get() for res in multi_res])if __name__ == '__main__': multicore() 12345678910111213141516171819202122232425def f(x): return x*xif __name__ == '__main__': # start 4 worker processes pool = Pool(processes=4) # print "[0, 1, 4,..., 81]" print(pool.map(f, range(10))) # print same numbers in arbitrary order for i in pool.imap_unordered(f, range(10)): print i # evaluate "f(20)" asynchronously res = pool.apply_async(f, (20,)) # runs in *only* one process print res.get(timeout=1) # prints "400" # evaluate "os.getpid()" asynchronously res = pool.apply_async(os.getpid, ()) # runs in *only* one process print res.get(timeout=1) # prints the PID of that process # launching multiple evaluations asynchronously *may* use more processes multiple_results = [pool.apply_async(os.getpid, ()) for i in range(4)] print [res.get(timeout=1) for res in multiple_results] # make a single worker sleep for 10 secs res = pool.apply_async(time.sleep, (10,)) try: print res.get(timeout=1) except TimeoutError: print "We lacked patience and got a multiprocessing.TimeoutError" 时间比较:123456789101112131415161718import timefrom multiprocessing import Pooldef job(x): time.sleep(1) return x * xif __name__ == '__main__': start_time = time.time() for i in range(5): job(i) end_time = time.time() print('Non-concurrent time:', (start_time - end_time)) end_time_1 = time.time() pl = Pool(4) result = pl.map(job, [i for i in range(5)]) pl.close() pl.join() end_time_2 = time.time() print('Concurrent time:', (end_time_2 - end_time_1)) 输出控制:12345678910import timefrom multiprocessing import Pooldef job(x): time.sleep(2) print(x)if __name__ == '__main__': pool = Pool(3) pool.map(job, [i for i in range(5)]) pool.close() pool.join() 那为什么又会有没这行和空行的情况呢? 因为有可能在执行第一个进程时, 刚要打印换行符时, 切换到另一个进程, 这样就极有可能两个数字打印到同一行, 并且再次切换回第一个进程时会打印一个换行符, 所以就会出现空行的情况. 实例并行处理某个目录下文件中的字符个数和行数, 并存入res.txt. 123456789101112131415161718192021222324import osimport timefrom multiprocessing import Pooldef get_file(path): file_list = [] for root, dirs, files in os.walk(path, topdown=True): for file in files: if file.endswith('.txt') or file.endswith('.md'): file_list.append(os.path.join(root, file)) return file_listdef count_file(file_path): with open(file_path, 'r') as f: content = f.readlines() print(file_path, len(content)) return len(content), file_pathif __name__ == '__main__': path = './' files = get_file(path) pool = Pool(5) result_list = pool.map(count_file, files) pool.close() pool.join() Pool与进程锁123456789101112131415def job(i): lck.acquire() print('ENIAC', i%7) sys.stdout.flush() time.sleep(1) lck.release()def lock_init(l): global lck lck = lif __name__ == '__main__': lock = Lock() pool = Pool(6, initializer=lock_init, initargs=(lock, )) pool.map(job, [num for num in range(20)]) pool.close() pool.join() 123456789def job(i): print('ENIAC', i%7) sys.stdout.flush() time.sleep(1)if __name__ == '__main__': pool = Pool(6) pool.map(job, [num for num in range(20)]) pool.close() pool.join() 注意比较上述两段程序的输出情况, 第一段一条一条输出, 第二段一次输出数条.]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>多进程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python 多进程 multiprocess(1)]]></title>
    <url>%2F2018%2F05%2F16%2Fmultiprocess-python-1%2F</url>
    <content type="text"><![CDATA[导言Unix/Linux 系统提供 fork() 系统调用, 该函数返回两次, 分别在父进程和子进程内返回, 子进程永远返回 0, 父进程返回子进程 ID.通常调用 fork()后, 会设计一个 if 结构, 如果返回值为 0, 说明处于子进程, 编码处理子进程工作, 如果返回值不为 0, 说明处于父进程, 编码处理父进程工作. 计算密集型 –&gt; 多进程. IO 密集型 –&gt; 多线程 对于Linux系统, 系统开机时建立的 init 进程的 pid 为 1, 其他所有进程都由 init 进程(或其子进程) fork 而来, 所有进程以 init 进程为根构成一个进程树(可以通过pstree命令查看). fork 进程的时候, 系统在内存中开辟一段新空间给新进程, 然后两个进程同时运行. 子进程终结时会通知父进程并清空自己所占据的内存, 在内核里留下退出信息(exit code). 父进程得知子进程终结后, 需要对子进程使用 wait 系统调用, wait 函数会从内核中取出子进程的退出信息, 并清空该信息在内核中占据的空间. 如果父进程早于子进程终结, 子进程变成孤儿进程, 孤儿进程会被过继给 init 进程, init 进程就成了该子进程的父进程, 由 init 进程负责该子进程终结时调用 wait 函数. 如果父进程不对子进程调用 wait 函数, 子进程成为僵尸进程. 僵尸进程积累时, 会消耗大量内存空间。 1234567import osprint "Process (%s) start" % os.getpid()pid = os.fork()if pid == 0: print 'I am child process (%s) and my parent is %s.' % (os.getpid(), os.getppid())else: print 'I (%s) just created a child process (%s).' % (os.getpid(), pid) multiprocessing模块使用跨平台第三方库 multiprocessing. Process object12345678910111213141516171819from __future__ import print_functionimport osimport sysimport multiprocessingfrom multiprocessing import Processimport timedef lazy(): time.sleep(3) print('Starting: name(%s) pid(%s)' % (multiprocessing.current_process().name, os.getpid())) sys.stdout.flush() print('Exiting: name(%s)' % multiprocessing.current_process().name) sys.stdout.flush()if __name__ == "__main__": l = Process(name='lazy', target=lazy) l.start() print("Start: name(__main__) pid(%s)" % os.getpid()) print("Exiting: name(__main__) pid(%s)" % os.getpid()) sys.stdout.flush() print('name(%s) is_alive: %s' % (l, l.is_alive())) 输出为:12345Start: name(__main__) pid(11292)Exiting: name(__main__) pid(11292)name(&lt;Process(daemon, started)&gt;) is_alive: TrueStarting: name(daemon) pid(12988)Exiting: name(daemon) 改成如下后:12345678910if __name__ == "__main__": l = Process(name='lazy', target=lazy) l.start() print('name(%s) is_alive: %s' % (d, d.is_alive())) l.join() print('name(%s) is_alive: %s' % (d, d.is_alive())) print("Start: name(__main__) pid(%s)" % os.getpid()) print("Exiting: name(__main__) pid(%s)" % os.getpid()) sys.stdout.flush() print('name(%s) is_alive: %s' % (l, l.is_alive())) 输出为:1234567name(&lt;Process(daemon, started)&gt;) is_alive: TrueStarting: name(daemon) pid(6580)Exiting: name(daemon)name(&lt;Process(daemon, stopped)&gt;) is_alive: FalseStart: name(__main__) pid(1304)Exiting: name(__main__) pid(1304)name(&lt;Process(daemon, stopped)&gt;) is_alive: False 守护进程将子进程设置为守护进程后, 父进程在退出时不会管子进程是否退出而直接退出. 123456789101112131415from multiprocessing import Processimport timedef func(): print("[start] child process, %s" % time.ctime()) sys.stdout.flush() time.sleep(2) print("[exit] child process, %s" % time.ctime())if __name__ == "__main__": print("[start] main process, %s" % time.ctime()) p = Process(target=func) p.daemon = True p.start() # p.join() time.sleep(1) print("[exit] main process, %s" % time.ctime()) 输出为:123[start] main process, Thu May 17 01:11:24 2018[start] child process, Thu May 17 01:11:24 2018[exit] main process, Thu May 17 01:11:25 2018 当将 p.daemon = True 注释掉后, 输出为:1234[start] main process, Thu May 17 01:12:44 2018[start] child process, Thu May 17 01:12:44 2018[exit] main process, Thu May 17 01:12:45 2018[exit] child process, Thu May 17 01:12:46 2018 进程退出状态可以通过 exitcode 属性获取进程的退出状态. == 0 —- 正常退出 > 0 —- 进程报错, 并以该 exitcode 退出 &lt; 0 —- the process was killed with a signal of -1 * exitcode 123456789101112131415161718192021222324252627282930from __future__ import print_functionimport osimport sysimport multiprocessingfrom multiprocessing import Processimport timedef exit_error(): sys.exit(1)def exit_ok(): returndef return_value(): return 1def raises(): raise RuntimeError('An error occur')def terminated(): time.sleep(3)if __name__ == '__main__': jobs = [] for f in [exit_error, exit_ok, return_value, raises, terminated]: print('[start]', f.func_name) j = Process(target=f, name=f.func_name) jobs.append(j) j.start() jobs[-1].terminate() for j in jobs: j.join() print('[exit] name(%s) exitcode(%s)' % (j.name, j.exitcode)) sys.stdout.flush() 输出为:12345678910111213141516171819[start] exit_error[start] exit_ok[start] return_value[start] raises[start] terminatedProcess raises:Traceback (most recent call last): File &quot;D:\Program Files\Python27\lib\multiprocessing\process.py&quot;, line 258, in _bootstrap self.run() File &quot;D:\Program Files\Python27\lib\multiprocessing\process.py&quot;, line 114, in run self._target(*self._args, **self._kwargs) File &quot;D:\SourceCode\python\app_crawl\main.py&quot;, line 19, in raises raise RuntimeError(&apos;An error occur&apos;)RuntimeError: An error occur[exit] name(exit_error) exitcode(1)[exit] name(exit_ok) exitcode(0)[exit] name(return_value) exitcode(0)[exit] name(raises) exitcode(1)[exit] name(terminated) exitcode(-15)]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>多进程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[列表 (Lists)]]></title>
    <url>%2F2018%2F04%2F22%2FDSA-list%2F</url>
    <content type="text"><![CDATA[引入使用单向链表进行列表数据结构构造, 实现上, 每个列表元素包含两个部分, 存储数据部分和存储指向下一个列表元素的指针部分. 最后一个元素的指针应为 NULL. 如下图所示: 设计列表]]></content>
      <categories>
        <category>Data Structures and Algorithm</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[时间/空间复杂度分析]]></title>
    <url>%2F2018%2F04%2F06%2FDSA-analysis%2F</url>
    <content type="text"><![CDATA[引入所谓时间复杂度粗略讲即是程序运行时间, 然而运行时间受很多因素影响 (平台, 硬件, 操作系统 …). 所以为了在数学上能统一定量分析, 需要一些假定: 加(减), 乘(除)等数值运算, 比较等逻辑运算, 赋值等表达式, return 语句的时间复杂度都为常数时间 (为1, one time unit). 现分析下面程序的时间复杂度作为示例: 123456789// e-1int Sum(int N) &#123; int i, S; S = 0; for(i = 1; i &lt;= N; i++) &#123; S += i * i * i; &#125; return S;&#125; 分析如下: 第 2 行声明或定义, 在编译期完成而非程序运行时期, 忽略时间; 第 3 行赋值, 时间为 1; 第 7 行返回值给调用的地方, 时间为 1; 第 4-6 为 for 循环, 第一次进入循环, i=1 (时间为 1). i &lt;= N (时间为 1). S+=i*i*i &lt;=&gt; S=S+i*i*i 包含两次乘法 (时间为 2), 一次加法 (时间为 1), 一次赋值 (时间为 1), 故这条语句总时间为 4. 之后, i 从 2 到 N 取值, 每次取值循环都包含: i++ (时间为 1), i &lt;= N (时间为 1), S+=i*i*i (时间为 4). 故 i 从 1 到 N 时, 每次循环时间都为 6, 故总时间为: 6N + 2(i第N次循环完成后,还要执行一次i++和i&lt;=N运算). 故 e-1 的时间复杂度为 6N + 4 = 6N + 2 + 2. 从 e-1 例子可以看出, 输入数据是给定的, 运算方式也固定, 即该时间复杂度不受输入数据的影响. 但在其它一些情形下, 相同的一段代码会随着输入数据分布不同产生不同的时间复杂度. 比如冒泡排序, 对输入序列 1 2 3 4 5 和 2 4 3 1 5 时间复杂度是不同的, 并且在生产环境中, 并不能事先知道下一条输入数据会是怎样的. 所以这种情况下所计算的时间就有很多可能, 会在一个范围内变化. 为衡量这种情况下的时间复杂度, 引入渐进符号. 复杂度记号$\Theta$ 记号 用 $\Theta(g(n))$表示以下函数集合: $\Theta$(g(n)) = {f(n): 存在正常数 $c_1$, $c_2$ 和 $n_0$, 使得对所有的 $n \geq n_0$, 有 $0 \leq c_1g(n) \leq f(n) \leq c_2g(n)$}, 通常记作 f(x)=$\Theta$(g(n)). $\Theta$ 记号给出函数上界与下界. 证明: $\frac{1}{2}n^2-3n=\Theta(n^2)$. 需确定 $c_1, c_2, n_0$ 的值, 使对所有 $n\geq n_0$, 有: $$c_1n^2\leq\frac{1}{2}n^2-3n\leq c_2n^2$$ $$c_1\leq\frac{1}{2}-\frac{3}{n}\leq c_2$$选择合适的 $n_0$ 便可求得 $c_1, c_2$. $O$ 记号 用 $O(g(n))$表示以下函数集合: $O$(g(n)) = {f(n): 存在正常数 $c$, 和 $n_0$, 使得对所有的 $n \geq n_0$, 有 $0 \leq f(n) \leq cg(n)$}, 通常记作 f(x)=$O$(g(n)). $\Omega$ 记号 用 $\Omega(g(n))$表示以下函数集合: $\Omega$(g(n)) = {f(n): 存在正常数 $c$, 和 $n_0$, 使得对所有的 $n \geq n_0$, 有 $0 \leq cg(n) \leq f(n)$}, 通常记作 f(x)=$\Omega$(g(n)). 其它时间复杂度记号参见算法导论一书. 常使用的是 $O$ 记号, 表征函数上界, 即最坏情况运行时间. 递归简述首先以阶乘为例: 123456789// e-2long int Factorial (n) &#123; if (n &lt;= 1) &#123; return 1; &#125; else &#123; return n * Factorial(n-1); &#125;&#125; 然后是斐波拉契数列为例: 123456789// e-3long int Fib (n) &#123; if (n &lt;= 1) &#123; return 1; &#125; else &#123; return Fib(n-1) + Fib(n-2); &#125;&#125; 简单分析其运行时间, 当 $n\geq 2$ 时, $T(n)=T(n-1)+T(n-2)+2$, 其中 2 是行 2 和行 6 的时间和. 现简单计算其时间复杂度, 由于斐波拉契通项公式为: $F(n) = F(n-1) + F(n-2), n \geq 2$. 故可知 $T(n) \geq F(n)$, 又因为 $F(n)\lt(\frac{5}{3})^n$, 进一步当 $n\geq4$时, $F(n)\geq(\frac{3}{2})^n$. 故可知 e-3 运行的时间是指数级的. 后面会给出另一个更高效的算法, 并解释为何 e-3 算法复杂度会这么高. 求解递归式三种方法一般有代入法, 递归树法, 主方法三种. 都可以求出算法的 $\Theta$ 和 $O$ 的渐近界. 代入法例 1: 求下面递归式的上界: $$T(n)=2T(\lfloor\frac{n}{2}\rfloor)+n$$ 猜想其解为 $T(n)=O(n\lg n)$; 根据 $O$ 的定义, 存在正常数 $c, n_0$, 使 $n\geq n_0$ 时满足 $0\leq T(n)\leq cn\lg n$, 故要找到这样的 $c, n_0$. 由递归表达式可推出 $2T(\lfloor n/2\rfloor)+n\leq cn\lg n$. 设上界对所有 $n\gt n_0$ 都成立, 当 $n_0=\lfloor n/2\rfloor$, 有 $T(\lfloor n/2\rfloor)\leq c\lfloor n/2\rfloor \lg\lfloor n/2\rfloor$. 代入得: $$T(n)\leq 2c\lfloor n/2\rfloor \lg\lfloor n/2\rfloor +n\leq cn\lg (n/2) +n$$$$cn\lg (n/2) +n=cn\lg n-cn\lg 2+n$$ 要 $$cn\lg n-cn\lg 2+n\leq cn\lg n$$ 只需 $c\geq 1$ 即可. 例 2: 求下面递归式的上界: $$T(n)=2T(\lfloor\frac{n}{2}\rfloor+17)+n$$ 递归树法以 $$T(n)=3T(\lfloor n/4\rfloor)+\Theta(n^2)$$ 为例说明递归树法. 主函数法形如: $$T(n)=aT(n/b)+f(n), a\geq1,b\gt1$$ 的递归式, 其中 $n/b$ 可解释为 $\lfloor n/b\rfloor$ 或者 $\lceil n/b\rceil$,由以下主定理给出解答: 若对某个常数 $\epsilon\gt0$ 有$f(n)=O(n^{log_b a-\epsilon})$, 则 $T(n)=\Theta(n^{log_b a})$. 若 $f(n)=\Theta(n^{log_b a})$, 则 $T(n)=\Theta(n^{log_b a}\lg n)$. 若对某个常数 $\epsilon\gt0$ 有$f(n)=\Omega(n^{log_b a+\epsilon})$, 且对某个常数 $c\lt1$ 和所有足够大的 n 有 $af(n/b)\leq cf(n)$, 则 $T(n)=\Theta(f(n))$. 例子: $$T(n)=9T(n/3)+n, [\Theta(n^2)]$$$$T(n)=T(2n/3)+1, [\Theta(\lg n)]$$$$T(n)=3T(n/4)+n\lg n, [\Theta(n\lg n)]$$$$T(n)=2T(n/2)+\Theta(n), [\Theta(n\lg n)]$$]]></content>
      <categories>
        <category>Data Structures and Algorithm</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[(DSA)序章]]></title>
    <url>%2F2018%2F04%2F05%2FDSA-xu%2F</url>
    <content type="text"><![CDATA[If you can’t explain it simply, you don’t understand it well enough. Talk is cheap, show me the code. 本硕皆非计算机相关专业, 然一直对代码有浓厚兴趣, 相关理论知识皆属课外自学, 所幸研究生期间做着深度学习相关研究, 也参与过数个前后端相关项目. 一直有个夙愿, 系统地将数据结构, 算法等相关基础知识学一遍. 而检验学习效果的除了上手写代码外, 还需要将所学输出出来. 所谓知行合一, the Feynman Technique 是也. 主要参考资料为: 算法导论 数据结构与算法分析(C语言描述) google 及其它 网上各种资源丰富, GitHub上亦有很多现成轮子, 但绝不简单复制, 草草了事, 自己没有理解或没有验证的绝不写. 私以为目前中文世界中大部分技术博客都是不合格的, 在写的过程中要探索何为技术博客写作?这一问题. 代码基于数据结构与算法分析(C语言描述)用C++所写, 由于编码经验与能力弱, 必有错漏和不规范的地方, 定不断努力提高.]]></content>
      <categories>
        <category>Data Structures and Algorithm</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[有没有什么适合普通人闲来思索的哲学问题？]]></title>
    <url>%2F2017%2F12%2F22%2Fzhexue%2F</url>
    <content type="text"><![CDATA[先祭出老先生壮壮胆。（哲学票友，一己之见）“不离日用常行内，直造先天未画前”王阳明先生用自己的经历告诉我们，即使对着一根竹子也可以产生哲学问题。先列举一些： 为什么要叠被子？为了整齐。把被子铺好（还可以透气）就不整齐了吗？什么是整齐？由叠被子可以想到军队里，军队里为什么要叠被子？ 王阳明先生帅不帅（仅就图片说，不知道这张图片有多少真实性）？帅有没有一个客观标准？如果有，这种主观的体验为什么会外化成较统一的标准？是就哪个范围说的，这个标准会不会随时间变化？如果会变化，是什么引起的这种变化？ 回想一下自己吃饭时，一般会有左边咀嚼还是右边还是两边同时，有可能想不起来，因为它已经变成了无意识的行为。我一天中还有哪些是无意识的？这些无意识的东西能不能构成我之为我而区别于其他？如果不能，那么在做这些无意识的事情时，能不能说是我在做？多大的程度上能说？ 关于红绿色盲，如果我们绝大多数人都是，而我们这种“正常的”视力占少数，关于红绿，是不是只是个名字代号不同而已？由此联想到假如现在发现了一种古文字，没有人能解出是什么意思，如果有人将这套古文字和我们使用的语言对应起来了，并且是自洽的。那我们能不能说我们理解了这套古文字。由此可以想象人类现有的科学知识有没有可能只是这样一种对应，且就目前来讲还是自洽的。同时我们的感官所感知和思维所知觉的和客观世界有没有可能只是一种对应，就世界的本来知识其实我们一无所知。 按照冯友兰先生的说法，哲学是思想思想的学问即反思的学问。所以可以从这个问题本身开始。分两个问题谈，1.哲学性的问题,2.哲学性的思考 什么问题是哲学问题？正常情况下，当我们产生一个问题或者说疑问时，这个问题或者疑惑一定有所指向。它指向既在，此在或者彼在（不只是指时间空间上的，也指逻辑上的，例如：“是人首先要是动物”，这个判断中的“首先”就是逻辑上的先后，而非时间上的）。 所谓指向此在意思是“X是什么”【“是，being”，是一个非常重要且深奥的西哲范畴，在此不做讨论】。这类问题一般是指向概念和事实，例如：什么是桌子？苏格拉底是谁？人是什么？这篇文章讲的是什么？（实的概念或事实），什么是正义？幸福是什么？何谓道德罪恶？·有灵魂有鬼吗？（虚的概念或事实） 指向既在意思是“X有什么根据？X的原因是什么？”。例如：天怎么这么冷？为什么苹果往下落？银杏叶为什么会变黄？ 指向彼在意思是“X还有哪些可能性？”（潜在的）。例如：两点之间直线距离最短是不是任何情况下成立？三角形角之和一定等于180°吗？ 说完问题，再说什么样的问题算是哲学问题。 网速怎么这么差？你是不是不喜欢我？这节课我是逃还是上呢？这些日常的琐碎的问题，如果寻求的只是日常的功能性的回答，都不能叫哲学性的问题。哲学的问题不在于问的问题是否是哲学界里的问题，（什么存在，此在，一与多，物自性，偶性，必然。。。）而在于是否有形而上的兴趣，倾向。 例如对网速怎么这么差这个问题，你可以思考这个问题本身，当你问这个问题时，你的心情此时一定是不爽的，由此你可以进一步关注你的情绪，为什么网速差会让你不爽？，然后你可以继续问这种不爽的情绪产生的机理是什么？我明白了这件事背后的道理能不能消解我这种不爽？我能真正控制自己的情绪吗？我的思维和情绪是一种什么关系？这样就可以一步一步深入下去，将一个无聊的牢骚变成一个有意思的问题。 哲学性的思考逻辑上的准备思方網，这个网站上介绍了一些比较好的批判式思维方法。找一本讲形式逻辑的书看看，推荐《普通逻辑》上海人民出版社。（教材式的，可能会有些许枯燥） 从桌上的杯子谈起身边的任何东西都可以产生哲学问题。“桌子上面有杯子”，这是一个事实描述，可以围绕这个描述不断的加一些限定修饰（性质）。先分解这个描述：有哪些主词实词，“桌子”，“杯子”，那就可以问什么是桌子和杯子。自己可以尝试给它们下定义，然后不断找出这种定义的漏洞，不停的丰富加深。如“杯子是一种盛水的器皿”，这个定义是就杯子的功能定义的，且是充分不必要的，我们可以说杯子可以用来盛水，但盛水的器皿不必然被称作杯子，又比如这个杯子破了个洞不能盛水了，但我们依然说这是个杯子。这不是文字游戏，当你追问这种问题时，差不多就可以算作是哲学性的思考了。“再考虑关系问题，“上面”是一个空间关系的描述，这种空间关系是怎么产生的，是因为在地球上引力向下吗？从太空的角度，能不能说月亮在地球上或者地球在月亮上？这种事物间的关系与事物各自的属性是独立的呢，还是分离的？如果是分离的，那我们是如何认识到这种关系的，它是在我们一出生就赋予给我们的吗？还是后天习得的？。。。（说的很混乱，见谅） 最后推荐两本书：南大学生写的，从一些日常问题着手慢慢进入一种哲学式的思考。所罗门的大问题从问题为起始点梳理了哲学史，是以问题为导向的。这两本书比较切合题主的问题。 关于作者1234var muzhi = &#123; nerdName : "木之", site : "https://www.zhihu.com/question/36840804/"&#125;]]></content>
      <categories>
        <category>哲学</category>
      </categories>
      <tags>
        <tag>哲学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cpp_iostream]]></title>
    <url>%2F2017%2F09%2F20%2Fcpp-iostream%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[python-lxml]]></title>
    <url>%2F2017%2F07%2F19%2Fpython-lxml%2F</url>
    <content type="text"><![CDATA[XPath语法12345678&lt;bookstore&gt; &lt;book&gt; &lt;title&gt;Harry Potter&lt;/title&gt; &lt;author&gt;J K. Rowling&lt;/author&gt; &lt;year&gt;2005&lt;/year&gt; &lt;price&gt;29.99&lt;/price&gt; &lt;/book&gt;&lt;/bookstore&gt; 路径表达式 描述 type bookstore 选取此节点的所有子节点 90 /bookstore 选取根元素bookstore。注释：假如路径起始于正斜杠( / )，则此路径始终代表到某元素的绝对路径 100 bookstore/book 选取属于bookstore的子元素的所有book元素 90 //book 选取所有book子元素，而不管它们在文档中的位置 bookstore//book 选择属于bookstore元素的后代的所有book元素，而不管它们位于bookstore之下的什么位置 //@lang 选取名为lang的所有属性 谓语 路径表达式 描述 type /bookstore/book[1] 选取属于bookstore子元素的第一个book元素 90 /bookstore/book[last()] 选取属于bookstore子元素的最后一个book元素 100 /bookstore/book[last()-1] 倒数第二个 90 /bookstore/book[position()&lt;3] 选取最前面的两个属于bookstore元素的子元素的book元素 //title[@lang] 选取所有拥有名为lang的属性的title元素 //title[@lang=’eng’] 选取所有title元素，且这些元素拥有值为eng的lang属性 /bookstore/book[price&gt;35.00] 选取 bookstore 元素的所有book元素，且其中的price元素的值须大于35.00 /bookstore/book[price&gt;35.00]/title 选取bookstore元素中的book元素的所有title元素，且其中的price元素的值须大于35.00 示例1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465import lxml.etree import sys html = '''&lt;html&gt; &lt;head&gt; &lt;meta name="content-type" content="text/html; charset=utf-8" /&gt; &lt;title&gt;友情链接查询 - 站长工具&lt;/title&gt; &lt;!-- uRj0Ak8VLEPhjWhg3m9z4EjXJwc --&gt; &lt;meta name="Keywords" content="友情链接查询" /&gt; &lt;meta name="Description" content="友情链接查询" /&gt; &lt;/head&gt; &lt;body&gt; &lt;h1 class="heading"&gt;Top News&lt;/h1&gt; &lt;p style="font-size: 200%"&gt;World News only on this page&lt;/p&gt; Ah, and here's some more text, by the way. &lt;p&gt;... and this is a parsed fragment ...&lt;/p&gt; &lt;a href="http://www.cydf.org.cn/" rel="nofollow" target="_blank"&gt;青少年发展基金会&lt;/a&gt; &lt;a href="http://www.4399.com/flash/32979.htm" target="_blank"&gt;洛克王国&lt;/a&gt; &lt;a href="http://www.4399.com/flash/35538.htm" target="_blank"&gt;奥拉星&lt;/a&gt; &lt;a href="http://game.3533.com/game/" target="_blank"&gt;手机游戏&lt;/a&gt; &lt;a href="http://game.3533.com/tupian/" target="_blank"&gt;手机壁纸&lt;/a&gt; &lt;a href="http://www.4399.com/" target="_blank"&gt;4399小游戏&lt;/a&gt; &lt;a href="http://www.91wan.com/" target="_blank"&gt;91wan游戏&lt;/a&gt; &lt;div class="news"&gt; 1. &lt;b&gt;无流量站点清理公告&lt;/b&gt; 2013-02-22&lt;br /&gt; 取不到的内容11 &lt;/div&gt; &lt;div class="news"&gt; 2. &lt;strong&gt;无流量站点清理公告&lt;/strong&gt; 2013-02-22&lt;br /&gt;取不到的内容22 &lt;/div&gt; &lt;div class="news"&gt; 3. &lt;span&gt;无流量站点清理公告&lt;/span&gt; 2013-02-22&lt;br /&gt;取不到的内容33 &lt;/div&gt; &lt;div class="news"&gt; 4. &lt;u&gt;无流量站点清理公告&lt;/u&gt; 2013-02-22&lt;br /&gt;取不到的内容44 &lt;/div&gt; &lt;/body&gt; &lt;/html&gt; ''' page = etree.HTML(html.decode('utf-8'))hrefs = page.xpath("//a") for href in hrefs: print href.get('href') print href.text.encode("utf-8") print '*'*10 ps = page.xpath("/html/body/p[@style='font-size: 200%']")for p in ps: print p.values() print p.text.encode('utf8') print '-'*10hard_get = page.xpath("//br")for hg in hard_get: print '---'+hg.tail.encode('utf8').strip()+'---' print '-'*10 html1 = """ &lt;html&gt;&lt;head&gt;&lt;title&gt;为什么len(y) &lt;= 1&lt;/title&gt;&lt;script&gt;var y = 1&lt;/script&gt;&lt;/head&gt;sample.&lt;html&gt; """ page1 = etree.HTML(html1.decode('utf8')) title = page1.xpath("//title")[0].text print 'title:%s'%title.encode('utf-8') print '-'*10 from lxml.html import clean]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[xx-net远程代理(阿里云)]]></title>
    <url>%2F2017%2F07%2F12%2Fxxnet-remote%2F</url>
    <content type="text"><![CDATA[后台服务启动假设你的XX-Net的目录在/home/yourName/XX-Net,那么在/etc/init.d目录下执行sudo ln -s /home/yourName/XX-Net/code/default/xx_net.sh xx_net.Tips: 如果你发现使用上面超链接的方式,在系统启动时xx_net的服务起不来,但是使用sudo service xx_net start却可以启动服务,而在dmesg|grep xx_net时,会发现有/etc/init.d/xx_net no such file or directory的错误,那你可能遇到了systemd的bug,解决办法是拷贝/home/yourName/XX-Net/code/default/xx_net.sh到/etc/init.d/xx_net,然后修改/etc/init.d/xx_net里的$PACKAGE_PATH=’/home/yourName/XX-Net/code/default’ 如果系统使用systemD 进行服务管理,则执行下面命令启用xx_net服务：sudo systemctl enable xx_net如果你是debian的系统,则使用下面命令启用xx_net服务:sudo update-rc.d enable xx_net启动xx-net：sudo service xx_net start停止xx-net：sudo service xx_net stop重启xx-net:sudo service xx_net restart查看XX-net状态：sudo service xx_net status也或者用下面命令更靠谱些：sudo netstat -tlanp|grep 8087日志保存在/var/log/messages文件中,用tail命令查看：tail -f /var/log/messages|grep xx_net 远程代理配置123456vim XX-NetRoot/data/launcher/config.yamlmodules:&#123; gae_proxy: &#123;auto_start: 1&#125; launcher:&#123; allow_remote_connect:1, control_port: 8085, proxy: pac, xxnet_port: 8087 &#125; x_tunnel: &#123;auto_start: 1&#125; 12345678vim XX-Net/data/gae_proxy/config.ini[gae]appid = chanid-001|chanid-002password =[listen]ip = 0.0.0.0 重启xx-net服务.]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[autossh反向连接]]></title>
    <url>%2F2017%2F05%2F24%2Fautossh-config%2F</url>
    <content type="text"><![CDATA[外网与内网连接 Port Forwarding(端口映射) Reverse Connection(反向连接)内网主机主动连接外网主机,NAT路由和防火墙内网host与外网host之间建立映射.但这种映射是由NAT路由自动维持的,不会持续下去,连接断开或网络不稳都会导致通信失效. ssh 实现反向连接 A: (内网)局域网内, IP 为 a.a.a.a, 用户名为 userA B: (外网)局域网外, 作为访问 A 的服务器, IP 为 b.b.b.b, 用户名为 userB C: 局域网内或者局域网外, IP 为 c.c.c.c, 用户名为 userC 实现 在 A 上建立 A 到 B 的反向连接. ssh -fCNR protB:a.a.a.a:portA userB@b.b.b.b. 此时, B 可以通过 ssh -p portB userA@localhost. 但是 C 不能通过 ssh userA@b.b.b.b -p portB 连接 A. 在 B 上建立 B 到 A 上的正向连接, 以实现和外网的通信. ssh -fCNL *:portB1:localhost:portB userB@localhost. portB1 用作本地转发的端口, 用来和外网通信, 并将数据转发到 portB, 实现从其他机器可以访问. * 表示接受来自任意机器的访问. 现在 C 可以通过 ssh -p portB1 userA@b.b.b.b 来访问 A. -fNCRL: -f – 后台运行. -C – 允许压缩数据. -N – 不执行任何命令. -R – 将端口绑定到远程服务器, 反向连接. -L – 将端口绑定到本地客户端, 正向连接. autossh实现持续反向连接现有内网主机A和外网主机B： A : localhostB : 120.27.104.101在A终端执行:ssh -NfR 8890:localhost:8888 user@120.27.104.101 -p 22,将A的8888端口和B的8890端口绑定,sshd的端口号为22. 要实现autossh还要安装sudo apt-get install autossh(在A host上),和sudo apt-get install openssh-server(在B host上). (1) 在主机A上123cd ~/.sshssh-keygenssh-copy-id user@120.27.104.101 编辑/etc/ssh/sshd_config,设置PermitRootLogin without-password,重启服务.(2) 在主机B上编辑/etc/ssh/sshd_config，添加GatewayPorts yes,重启服务/etc/init.d/ssh restart.(3) 在主机A终端执行autossh -M 30021 -NR *:8890:localhost:8888 user@120.27.104.101,通过端口30021监视连接状态,若断开则重连,后台运行在末尾加上&amp;即可.]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>反向代理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux专题(3):进程间通信]]></title>
    <url>%2F2017%2F05%2F09%2Flinux-index2%2F</url>
    <content type="text"><![CDATA[信号可以看作一种粗糙的进程间通信(IPC, interprocess communication)的方式,用以向进程封闭的内存空间传递信息.为了让进程间传递更多的信息量,我们需要其他的进程间通信方式.这些进程间通信方式可以分为两种: 管道(PIPE)机制.在Linux文本流中,我们提到可以使用管道将一个进程的输出和另一个进程的输入连接起来,从而利用文件操作API来管理进程间通信.在shell中,我们经常利用管道将多个进程连接在一起,从而让各个进程协作,实现复杂的功能. 传统IPC (interprocess communication).我们主要是指消息队列(message queue),信号量(semaphore),共享内存(shared memory).这些IPC的特点是允许多进程之间共享资源,这与多线程共享heap和global data相类似.由于多进程任务具有并发性 (每个进程包含一个进程,多个进程的话就有多个线程),所以在共享资源的时候也必须解决同步的问题. 管道与FIFO文件一个原始的IPC方式是所有的进程通过一个文件交流.比如我在纸(文件)上写下我的名字和年纪.另一个人读这张纸,会知道我的名字和年纪.他也可以在同一张纸上写下他的信息,而当我读这张纸的话,同样也可以知道别人的信息.但是,由于硬盘读写比较慢,所以这个方式效率很低.那么,我们是否可以将这张纸放入内存中以提高读写速度呢？比如在Python子进程中使用Popen和PIPE,在C语言中也有popen库函数来实现管道 (shell中的管道就是根据此编写的).管道是由内核管理的一个缓冲区(buffer),相当于我们放入内存中的一个纸条.管道的一端连接一个进程的输出.这个进程会向管道中放入信息.管道的另一端连接一个进程的输入,这个进程取出被放入管道的信息.一个缓冲区不需要很大,它被设计成为环形的数据结构,以便管道可以被循环利用.当管道中没有信息的话,从管道中读取的进程会等待,直到另一端的进程放入信息.当管道被放满信息的时候,尝试放入信息的进程会等待,直到另一端的进程取出信息.当两个进程都终结的时候,管道也自动消失.从原理上,管道利用fork机制建立.从而让两个进程可以连接到同一个PIPE上.最开始的时候,上面的两个箭头都连接在同一个进程Process 1上(连接在Process 1上的两个箭头).当fork复制进程的时候,会将这两个连接也复制到新的进程(Process 2).随后,每个进程关闭自己不需要的一个连接 (两个黑色的箭头被关闭; Process 1关闭从PIPE来的输入连接,Process 2关闭输出到PIPE的连接),这样,剩下的红色连接就构成了如图的PIPE.由于基于fork机制,所以管道只能用于父进程和子进程之间,或者拥有相同祖先的两个子进程之间 (有亲缘关系的进程之间).为了解决这一问题,Linux提供了FIFO方式连接进程.FIFO又叫做命名管道(named PIPE).FIFO (First in, First out)为一种特殊的文件类型,它在文件系统中有对应的路径.当一个进程以读(r)的方式打开该文件,而另一个进程以写(w)的方式打开该文件,那么内核就会在这两个进程之间建立管道,所以FIFO实际上也由内核管理,不与硬盘打交道.之所以叫FIFO,是因为管道本质上是一个先进先出的队列数据结构,最早放入的数据被最先读出来(好像是传送带,一头放货,一头取货),从而保证信息交流的顺序.FIFO只是借用了文件系统来为管道命名.写模式的进程向FIFO文件中写入,而读模式的进程从FIFO文件中读出.当删除FIFO文件时,管道连接也随之消失.FIFO的好处在于我们可以通过文件的路径来识别管道,从而让没有亲缘关系的进程之间建立连接. 消息队列(message queue)与PIPE相类似.它也是建立一个队列,先放入队列的消息被最先取出.不同的是,消息队列允许多个进程放入消息,也允许多个进程取出消息.每个消息可以带有一个整数识别符(message_type).你可以通过识别符对消息分类 (极端的情况是将每个消息设置一个不同的识别符).某个进程从队列中取出消息的时候,可以按照先进先出的顺序取出,也可以只取出符合某个识别符的消息(有多个这样的消息时,同样按照先进先出的顺序取出).消息队列与PIPE的另一个不同在于它并不使用文件API.最后,一个队列不会自动消失,它会一直存在于内核中,直到某个进程删除该队列. 多进程协作可以帮助我们充分利用多核和网络时代带来的优势.多进程可以有效解决计算瓶颈的问题.互联网通信实际上也是一个进程间通信的问题,只不过这多个进程分布于不同的电脑上.网络连接是通过socket实现的.由于socket内容庞大,所以我们不在这里深入.一个小小的注解是,socket也可以用于计算机内部进程间的通信.]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux专题(2):多线程与同步]]></title>
    <url>%2F2017%2F05%2F09%2Flinux-index1%2F</url>
    <content type="text"><![CDATA[并发多线程相当于一个并发(concunrrency)系统.并发系统一般同时执行多个任务.如果多个任务可以共享资源,特别是同时写入某个变量的时候,就需要解决同步的问题.比如说,我们有一个多线程火车售票系统,用全局变量i存储剩余的票数.多个线程不断地卖票(i = i - 1),直到剩余票数为0.所以每个都需要执行如下操作:123456789/*mu is a global mutex*/// 伪C代码while (1) &#123; /*infinite loop*/ if (i != 0) i = i -1; else &#123; printf("no more tickets"); exit(); &#125;&#125; 这里的if结构会给CPU两个指令, 一个是判断是否有剩余的票(i != 0), 一个是卖票 (i = i -1).某个线程会先判断是否有票(比如说此时i为1),但两个指令之间存在一个时间窗口,其它线程可能在此时间窗口内执行卖票操作(i = i -1),导致该线程卖票的条件不再成立.但该线程由于已经执行过了判断指令,所以无从知道i发生了变化,所以继续执行卖票指令,以至于卖出不存在的票 (i成为负数).对于一个真实的售票系统来说,这将成为一个严重的错误 (售出了过多的票,火车爆满). 在并发情况下,指令执行的先后顺序由内核决定.同一个线程内部,指令按照先后顺序执行,但不同线程之间的指令很难说清除哪一个会先执行.如果运行的结果依赖于不同线程执行的先后的话,那么就会造成竞争条件(race condition),在这样的状况下,计算机的结果很难预知.我们应该尽量避免竞争条件的形成.最常见的解决竞争条件的方法是将原先分离的两个指令构成不可分隔的一个原子操作(atomic operation),而其它任务不能插入到原子操作中. 多线程同步对于多线程程序来说,同步(synchronization)是指在一定的时间内只允许某一个线程访问某个资源 .而在此时间内,不允许其它的线程访问该资源.我们可以通过互斥锁(mutex),条件变量(condition variable)和读写锁(reader-writer lock)来同步资源. 互斥锁互斥锁是一个特殊的变量,它有锁上(lock)和打开(unlock)两个状态.互斥锁一般被设置成全局变量.打开的互斥锁可以由某个线程获得.一旦获得,这个互斥锁会锁上,此后只有该线程有权打开. 条件变量条件变量是另一种常用的变量.它也常常被保存为全局变量,并和互斥锁合作.假设这样一个状况: 有100个工人,每人负责装修一个房间.当有10个房间装修完成的时候,老板就通知相应的十个工人一起去喝啤酒.我们如何实现呢？老板让工人在装修好房间之后,去检查已经装修好的房间数.但多线程条件下,会有竞争条件的危险.也就是说,其他工人有可能会在该工人装修好房子和检查之间完成工作.采用下面方式解决：123456789101112/*mu: global mutex, cond: global codition variable, num: global int*/// 伪C代码mutex_lock(mu)num = num + 1; /*worker build the room*/if (num &lt;= 10) &#123; /*worker is within the first 10 to finish*/ cond_wait(mu, cond); /*wait*/ printf("drink beer");&#125;else if (num = 11) &#123; /*workder is the 11th to finish*/ cond_broadcast(mu, cond); /*inform the other 9 to wake up*/&#125;mutex_unlock(mu); 上面使用了条件变量.条件变量除了要和互斥锁配合之外,还需要和另一个全局变量配合(这里的num, 也就是装修好的房间数).这个全局变量用来构成各个条件.具体思路如下.我们让工人在装修好房间(num = num + 1)之后,去检查已经装修好的房间数( num &lt; 10 ).由于mu被锁上,所以不会有其他工人在此期间装修房间(改变num的值).如果该工人是前十个完成的人,那么我们就调用cond_wait()函数.cond_wait()做两件事情,一个是释放mu,从而让别的工人可以建房.另一个是等待,直到cond的通知.这样的话,符合条件的线程就开始等待.当有通知(第十个房间已经修建好)到达的时候,condwait()会再次锁上mu.线程的恢复运行,执行下一句prinft(“drink beer”) (喝啤酒！).从这里开始,直到mutex_unlock(),就构成了另一个互斥锁结构.那么,前面十个调用cond_wait()的线程如何得到的通知呢？我们注意到elif if,即修建好第11个房间的人,负责调用cond_broadcast().这个函数会给所有调用cond_wait()的线程放送通知,以便让那些线程恢复运行.条件变量特别适用于多个线程等待某个条件的发生.如果不使用条件变量,那么每个线程就需要不断尝试获得互斥锁并检查条件是否发生,这样大大浪费了系统的资源. 读写锁读写锁与互斥锁非常相似.r、RW lock有三种状态: 共享读取锁(shared-read), 互斥写入锁(exclusive-write lock), 打开(unlock).后两种状态与之前的互斥锁两种状态完全相同.一个unlock的RW lock可以被某个线程获取R锁或者W锁.如果被一个线程获得R锁,RW lock可以被其它线程继续获得R锁,而不必等待该线程释放R锁.但是,如果此时有其它线程想要获得W锁,它必须等到所有持有共享读取锁的线程释放掉各自的R锁.如果一个锁被一个线程获得W锁,那么其它线程,无论是想要获取R锁还是W锁,都必须等待该线程释放W锁.这样,多个线程就可以同时读取共享资源.而具有危险性的写入操作则得到了互斥锁的保护. 需要同步并发系统,这为程序员编程带来了难度.但是多线程系统可以很好的解决许多IO瓶颈的问题.比如我们监听网络端口.如果我们只有一个线程,那么我们必须监听,接收请求,处理,回复,再监听.如果我们使用多线程系统,则可以让多个线程监听.当我们的某个线程进行处理的时候,我们还可以有其他的线程继续监听,这样,就大大提高了系统的利用率.在数据越来越大,服务器读写操作越来越多的今天,这具有相当的意义.多线程还可以更有效地利用多CPU的环境.(就像做饭一样,不断切换去处理不同的菜.)]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux专题(1)]]></title>
    <url>%2F2017%2F05%2F09%2Flinux-index%2F</url>
    <content type="text"><![CDATA[文件系统的实现观察常见存储设备.最开始的区域是MBR,用于Linux开机启动.剩余的空间可能分成数个分区(partition).每个分区有一个相关的分区表(Partition table),记录分区的相关信息.这个分区表是储存在分区之外的.分区表说明了对应分区的起始位置和分区的大小.我们在Windows系统常常看到C分区、D分区等.Linux系统下也可以有多个分区,但都被挂载在同一个文件系统树上.数据被存入到某个分区中.一个典型的Linux分区(partition)包含有下面各个部分:分区的第一个部分是启动区(Boot block),它主要是为计算机开机服务的.Linux开机启动后,会首先载入MBR,随后MBR从某个硬盘的启动区加载程序.该程序负责进一步的操作系统的加载和启动.为了方便管理,即使某个分区中没有安装操作系统,Linux也会在该分区预留启动区.启动区之后的是超级区(Super block).它存储有文件系统的相关信息,包括文件系统的类型,inode的数目,数据块的数目.随后是多个inodes,它们是实现文件存储的关键.在Linux系统中,一个文件可以分成几个数据块存储.每个文件对应一个inode,这个inode中包含多个指针,指向属于该文件各个数据块.最后一部分,就是真正储存数据的数据块们(data blocks)了. inode一个文件除了自身的数据之外,还有一个附属信息,即文件的元数据(metadata).这个元数据用于记录文件的许多信息,比如文件大小,拥有人,所属的组,修改日期等等.元数据并不包含在文件的数据中,而是由操作系统维护的.事实上,这个所谓的元数据就包含在inode中.我们可以用$ls -l filename来查看这些元数据.正如我们上面看到的,inode所占据的区域与数据块的区域不同.每个inode有一个唯一的整数编号(inode number)表示.inode储存由一些指针,这些指针指向存储设备中的一些数据块,文件的内容就储存在这些数据块中.当Linux想要打开一个文件时,只需要找到文件对应的inode,然后沿着指针,将所有的数据块收集起来,就可以在内存中组成一个文件的数据了.inode并不是组织文件的唯一方式.最简单的组织文件的方法,是把文件依次顺序的放入存储设备,DVD就采取了类似的方式.但如果有删除操作,删除造成的空余空间夹杂在正常文件之间,很难利用和管理.复杂的方式可以使用链表,每个数据块都有一个指针,指向属于同一文件的下一个数据块.这样的好处是可以利用零散的空余空间,坏处是对文件的操作必须按照线性方式进行.如果想随机存取,那么必须遍历链表,直到目标位置.在Linux下,可以使用$stat filename,来查询某个文件对应的inode编号. FAT系统是将上面链表的指针取出,放入到内存的一个数组中.这样,FAT可以根据内存的索引,迅速的找到一个文件.这样做的主要问题是,索引数组的大小与数据块的总数相同.因此,存储设备很大的话,这个索引数组会比较大./var/test.txt: 文件共享在Linux的进程中,当我们打开一个文件时,返回的是一个文件描述符.这个文件描述符是一个数组的下标,对应数组元素为一个指针.有趣的是,这个指针并没有直接指向文件的inode,而是指向了一个文件表格,再通过该表格,指向加载到内存中的目标文件的inode.如下图,一个进程打开了两个文件.可以看到,每个文件表格中记录了文件打开的状态(status flags),比如只读,写入等,还记录了每个文件的当前读写位置(offset).当有两个进程打开同一个文件时,可以有两个文件表格,每个文件表格对应的打开状态和当前位置不同,从而支持一些文件共享的操作,比如同时读取.要注意的是进程fork之后的情况,子进程将只复制文件描述符的数组,而和父进程共享内核维护的文件表格和inode.此时要特别小心程序的编写.]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[caffe源码阅读(1)--protobuf]]></title>
    <url>%2F2017%2F05%2F06%2Fcaffe-sourcecodes%2F</url>
    <content type="text"></content>
      <categories>
        <category>CAFFE</category>
      </categories>
      <tags>
        <tag>深度学习 caffe</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[闲情偶记]]></title>
    <url>%2F2017%2F04%2F02%2Fbook-store%2F</url>
    <content type="text"></content>
      <categories>
        <category>闲情偶记</category>
      </categories>
      <tags>
        <tag>杂记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python正则表达式]]></title>
    <url>%2F2017%2F03%2F20%2Fpython-regexp%2F</url>
    <content type="text"><![CDATA[正则表达式的语法规则 数量词的贪婪模式与非贪婪模式正则表达式通常用于在文本中查找匹配的字符串.Python里数量词默认是贪婪的(在少数语言里也可能是默认非贪婪),总是尝试匹配尽可能多的字符:非贪婪的则相反,总是尝试匹配尽可能少的字符.例如:正则表达式ab*如果用于查找abbbc,将找到abbb.而如果使用非贪婪的数量词ab*?,将找到a.注:我们一般使用非贪婪模式来提取.]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python爬虫系列(1)]]></title>
    <url>%2F2017%2F03%2F20%2Fpython-craw%2F</url>
    <content type="text"><![CDATA[CookieCookie,指某些网站为了辨别用户身份,进行session跟踪而储存在用户本地终端上的数据,通常经过加密.比如有些网站需要登录后才能访问某个页面,在登录之前,抓取某个页面内容是不允许的.可以利用Urllib2库保存登录的Cookie,然后再抓取其他页面. Opener获取一个URL时使用一个opener(urllib2.OpenerDirector的实例),urlopen为默认opener.需要创建更一般的opener来实现对Cookie的设置. Cookielibcookielib模块的主要作用是提供可存储cookie的对象,以便于与urllib2模块配合使用来访问Internet资源.可以利用本模块的CookieJar类的对象来捕获cookie并在后续连接请求时重新发送,比如可以实现模拟登录功能.该模块主要的对象有CookieJar,FileCookieJar,MozillaCookieJar,LWPCookieJar.它们的关系：CookieJar —-派生—-&gt;FileCookieJar—-派生—–&gt;MozillaCookieJar和LWPCookieJar.获取Cookie保存到变量1234567891011121314import urllib2import cookielib#声明一个CookieJar对象实例来保存cookie#将cookie保存到了cookie这个变量中cookie = cookielib.CookieJar()#利用urllib2库的HTTPCookieProcessor对象来创建cookie处理器handler=urllib2.HTTPCookieProcessor(cookie)#通过handler来构建openeropener = urllib2.build_opener(handler)#此处的open方法同urllib2的urlopen方法，也可以传入requestresponse = opener.open('http://www.baidu.com')for item in cookie: print 'Name = '+item.name print 'Value = '+item.value 保存Cookie到文件12345678910111213141516import cookielibimport urllib2#ignore_discard的意思是即使cookies将被丢弃也将它保存下来,ignore_expires#意思是如果在该文件中cookies已经存在,则覆盖原文件写入#设置保存cookie的文件，同级目录下的cookie.txtfilename = 'cookie.txt'#声明一个MozillaCookieJar对象实例来保存cookie，之后写入文件cookie = cookielib.MozillaCookieJar(filename)#利用urllib2库的HTTPCookieProcessor对象来创建cookie处理器handler = urllib2.HTTPCookieProcessor(cookie)#通过handler来构建openeropener = urllib2.build_opener(handler)#创建一个请求，原理同urllib2的urlopenresponse = opener.open("http://www.baidu.com")#保存cookie到文件cookie.save(ignore_discard=True, ignore_expires=True) 从文件中获取Cookie并访问12345678910111213import cookielibimport urllib2 #创建MozillaCookieJar实例对象cookie = cookielib.MozillaCookieJar()#从文件中读取cookie内容到变量cookie.load('cookie.txt', ignore_discard=True, ignore_expires=True)#创建请求的requestreq = urllib2.Request("http://www.baidu.com")#利用urllib2的build_opener方法创建一个openeropener = urllib2.build_opener(urllib2.HTTPCookieProcessor(cookie))response = opener.open(req)print response.read() 利用cookie模拟网站登录1234567891011121314151617181920212223import urllibimport urllib2import cookielib filename = 'cookie.txt'#声明一个MozillaCookieJar对象实例来保存cookie，之后写入文件cookie = cookielib.MozillaCookieJar(filename)opener = urllib2.build_opener(urllib2.HTTPCookieProcessor(cookie))postdata = urllib.urlencode(&#123; 'stuid':'201200131012', 'pwd':'23342321' &#125;)#登录教务系统的URLloginUrl = 'http://jwxt.sdu.edu.cn:7890/pls/wwwbks/bks_login2.login'#模拟登录，并把cookie保存到变量result = opener.open(loginUrl,postdata)#保存cookie到cookie.txt中cookie.save(ignore_discard=True, ignore_expires=True)#利用cookie请求访问另一个网址，此网址是成绩查询网址gradeUrl = 'http://jwxt.sdu.edu.cn:7890/pls/wwwbks/bkscjcx.curscopre'#请求访问成绩查询网址result = opener.open(gradeUrl)print result.read()]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[caffe配置]]></title>
    <url>%2F2017%2F01%2F06%2Fcaffe-config%2F</url>
    <content type="text"><![CDATA[安装openCV 安装CUDA 安装依赖库（一）：$ lspci | grep -i nvidia 12$ sudo apt-get install libprotobuf-dev libleveldb-dev libsnappy-dev libopencv-dev libhdf5-serial-dev protobuf-compiler$ sudo apt-get install --no-install-recommends libboost-all-dev 安装ATLAS：(可以安装OpenBLAS 或 MKL，以提升CPU性能，但是要修改caffe中Makefile文件…) 1$ sudo apt-get install libatlas-base-dev 安装openCV(ubuntu14.04)搭建编译环境：sudo apt-get install build-essential安装依赖库：12$ sudo apt-get install cmake git libgtk2.0-dev pkg-config libavcodec-dev libavformat-dev libswscale-dev$ sudo apt-get install python-dev python-numpy libtbb2 libtbb-dev libjpeg-dev libpng-dev libtiff-dev libjasper-dev libdc1394-22-dev 下载OpenCV3.0-alpha版本：1234$ mkdir ~/opencv$ cd ~/opencv$ wget https://github.com/Itseez/opencv/archive/3.0.0-alpha.zip -O opencv-3.0.0-alpha.zip$ unzip opencv-3.0.0-alpha.zip 安装opencv：123456$ cmake .$ sudo make$ sudo make install$ sudo /bin/bash -c 'echo "/usr/local/lib" &gt; /etc/ld.so.conf.d/opencv.conf'$ sudo ldconfig[[如果cmake过程中提示：ippicv_linux_20141027.tgz的hash码不对，则将下载的ippicv_linux_20141027.tgz手动复制到 opencv-3.0.0-beta/3rdparty/ippicv/downloads/linux-8b449a536a2157bcad08a2b9f266828b文件夹中，重新cmake即可]] 可能需要的配置：1)sudo vim /etc/ld.so.conf.d/opencv.conf在其后加入/usr/local/lib;然后sudo ldconfig.2)添加环境变量123PKG_CONFIG_PATH=$PKG_CONFIG_PATH:/usr/local/lib/pkgconfigexport PKG_CONFIG_PATH 3)查看是否配置成功pkg-config --cflags opencv,pkg-config --libs opencv编译samples程序：123456789$ cd ~/opencv/samples$ sudo cmake .$ sudo make -j $(nproc)运行测试程序：alpha版本：# 注：使用alpha版本，images在opencv/cpp文件夹下$ cd cpp/$ ./cpp-example-facedetect lena.jpg 编译写好的Cpp代码:g++ test.cpp -o test pkg-config --cflags --libs opencv 安装依赖库（二）： 1$ sudo apt-get install libgflags-dev libgoogle-glog-dev liblmdb-dev 下载Caffe： 12$ cd ~$ git clone git://github.com/BVLC/caffe.git 123456789a、修改(caffe)Makefile，在LIBRARIES += glog gflags protobuf leveldb snappy \lmdb boost_system hdf5_hl hdf5 m \opencv_core opencv_highgui opencv_imgproc opencv_imgcodecs处加入后面的opencv_imgcodecs，因为opencv3.0.0把imread相关函数放到imgcodecs.lib中了（原来是imgproc.lib）b、修改caffe/examples/cpp_classification/classification.cpp文件，加入：#include &lt;opencv2/imgproc/types_c.h&gt;#include &lt;opencv2/objdetect/objdetect_c.h&gt;否则会出现”CV_BGR2GRAY”的错误 编译Caffe： 123456$ cd ~/caffe$ cp Makefile.config.example Makefile.config# 修改Makefile.config文件：去掉CPU_ONLY:= 1的注释$ make all$ make test$ make runtest 配置pycaffe： 123456789101112131415161718(安装依赖库)$ sudo apt-get install python-numpy python-scipy python-matplotlib python-sklearn python-skimage python-h5py python-protobuf python-leveldb python-networkx python-nose python-pandas python-gflags Cython ipython$ sudo apt-get install protobuf-c-compiler protobuf-compiler(编译)$ cd ~/caffe$ make pycaffe(添加~/caffe/Python到$PYTHONPATH)$ sudo gedit /etc/profile# 末尾添加： export PYTHONPATH=/path/to/caffe/python:$PYTHONPATH# 用完整路径，不要用~$ source /etc/profile # 使之生效(测试是否可以引用)$ pythonPython 2.7.6 (default, Jun 22 2015, 17:58:13) [GCC 4.8.2] on linux2Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.&gt;&gt;&gt; import caffe&gt;&gt;&gt; 安装CUDA(包含有驱动) 验证硬件支持GPU CUDA，只要型号存在于https://developer.nvidia.com/cuda-gpus，就没问题 Download the NVIDIA CUDA Toolkit下载地址：https://developer.nvidia.com/cuda-toolkit验证地址：https://developer.nvidia.com/rdp/cuda-rc-checksums$ md5sum filename例如：md5sum cuda_7.0.28_linux.run ，这个文件的正确 md5 =312aede1c3d1d3425c8aa67bbb7a55e 需要的库sudo apt-get install freeglut3-dev build-essential libx11-dev libxmu-dev libxi-dev libgl1-mesa-glx libglu1-mesa-dev 如果安装过nvidia其它版本则先卸载，sudo nvidia-uninstall,清除nvidia相关的库sudo apt-get --purge remove nvidia-* Graphical Interface Shutdown,退出GUI,也就是X-Win(桌面管理器)界面,操作方法是:同时按:CTRL+ALT+F1（F2-F6），切换到TTY1-6命令行模式.关闭桌面服务:$ sudo service lightdm stop(装驱动前须禁用lightdm) 禁用nouveau驱动,# sudo vi /etc/modprobe.d/blacklist-nouveau.conf,输入123blacklist nouveauoptions nouveau modset=0保存退出（:wq) 然后执行# sudo update-initramfs -u,执行 lspci | grep nouveau查看是否有内容,如果没有内容,说明禁用成功,如果有内容,就重启一下再查看.重启后,进入登录界面的时候,不要登录进入桌面,直接按Ctrl+Alt+F1进入命令提示符. 安装完成后,重启,然后用ls查看一下,是否生成了四个左右以nvidia开头的文件夹# ls /dev/nvidia*,如果有,说明安装成功了,如果没有,可能不成功,需要卸载重装.卸载命令如下：# sudo /usr/local/cuda-7.5/bin/uninstall_cuda_7.5.pl,# sudo /usr/bin/nvidia-uninstall,如果你还不放心是否安装成功,请参考其它教程,编译Samples进行测试,最后,配置环境变量,# sudo vi /etc/profile,export PATH=/usr/local/cuda-7.5/bin:$PATH,export LD_LIBRARY_PATH=/usr/local/cuda-7.5/lib64:$LD_LIBRARY_PATH保存退出,至此cuda 7.5安装完毕.nvcc --version cuda samples/usr/local/cuda-7.5/samplescd /home/xuezhisd/NVIDIA_CUDA-7.0_Samples编译 make （安装命令 sudo apt-get install cmake)编译完毕，切换release目录cd ./bin/x86_64/linux/release检验是否成功运行实例 ./deviceQuery./deviceQuery 查看CUDA计算容量：$ ./~/cuda/NVIDIA_CUDA-7.0_Samples/bin/x86_64/linux/release/deviceQuery查看CUDA Capability Major/Minor version number这一项，为5.2在Makefile.config文件中，修改CUDA_ARCH := -gencode arch=compute_20,code=sm_20 \ -gencode arch=compute_20,code=sm_21 \ -gencode arch=compute_30,code=sm_30 \ -gencode arch=compute_35,code=sm_35 \ -gencode arch=compute_50,code=sm_50 \ -gencode arch=compute_52,code=sm_52 \ -gencode arch=compute_50,code=compute_50]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>深度学习 caffe</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LINUX TRICK & TRAP]]></title>
    <url>%2F2016%2F12%2F11%2Flinux-index0%2F</url>
    <content type="text"><![CDATA[环境配置 ubuntu软件安装 apt&amp;dpkg ubuntu nginx配置 LNMP配置 环境变量 环境配置ubuntu软件安装apt&amp;dpkg(1)apt-get install安装应用程序(apt-get理论上是要求能够联网,但是如果制作了本地源,就不需要联网.下载的deb文件都会存放在/var/cache/apt/archives/下.)apt-get install( -d 仅下载,-f 强制安装.)apt-get remove1234567apt-get remove --purge xxx # 移除应用及配置apt-get autoremove # 移除没用的包apt-cache depends xxx(正向依赖)apt-cache rdepends xxx(方向依赖，被依赖)apt-cache show &lt;pkg_name&gt; # 显示软件包pkg_name的详细信息sudo apt-get --reinstall install xxx=xxx.1.2.3(即重新安装该包为1.2.3版本)apt-get install --reinstall &lt;pkg&gt; # 重新安装软件包&lt;pkg&gt; apt-get update更新软件信息数据库.apt-get upgrade进行系统升级.(2)dpkg安装deb包12345678910dpkg -i package.deb 安装包dpkg -r package 删除包dpkg -P package 删除包（包括配置文件）dpkg -L package 列出与该包关联的文件dpkg -l package 显示该包的版本dpkg –unpack package.deb 解开 deb 包的内容dpkg -S keyword 搜索所属的包内容dpkg -l 列出当前已安装的包dpkg -c package.deb 列出 deb 包的内容dpkg –configure package 配置包 ubuntu nginx配置 安装apt-get install nginx 安装后文件结构/etc/nginx –&gt;配置文件/etc/nginx/sites-available –&gt;每个虚拟主机/usr/sbin/nginx –&gt;程序文件/var/log/nginx –&gt;日志文件/etc/init.d/ –&gt;启动脚本 启动nginxsudo /etc/init.d/nginx start，若端口占用则:修改文件：/etc/nginx/sites-available/default,去掉 listen 前面的#号。 修改nginx.conf 1sudo vim etc/nginx/nginx.conf 在http{}中这两行代码前（include /etc/nginx/conf.d/*.conf;include /etc/nginx/sites-enabled/*;）加入一下代码:123456789101112131415161718192021222324252627282930313233client_max_body_size 50m;#缓冲区代理缓冲用户端请求的最大字节数,可以理解为保存到本地再传给用户client_body_buffer_size 256k;client_header_timeout 3m;client_body_timeout 3m;send_timeout 3m;proxy_connect_timeout 300s;#nginx跟后端服务器连接超时时间(代理连接超时)proxy_read_timeout 300s;#连接成功后，后端服务器响应时间(代理接收超时)proxy_send_timeout 300s;proxy_buffer_size 64k;#设置代理服务器（nginx）保存用户头信息的缓冲区大小proxy_buffers 4 32k;#proxy_buffers缓冲区，网页平均在32k以下的话，这样设置proxy_busy_buffers_size 64k;#高负荷下缓冲大小（proxy_buffers*2）proxy_temp_file_write_size 64k;#设定缓存文件夹大小，大于这个值，将从upstream服务器传递请求，而不缓冲到磁盘proxy_ignore_client_abort on;#不允许代理端主动关闭连接server &#123; listen 80; server_name localhost;location / &#123; root html; index index.html index.htm;&#125; error_page 500 502 503 504 /50x.html;location = /50x.html &#123; root html;&#125;&#125; 配置vhost.conf默认无此文件，sudo vim /etc/nginx/conf.d/vhost.conf加入以下代码： 12345678910111213141516171819202122232425262728server&#123; listen 80; server_name a.com; location / &#123; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://127.0.0.1:200; &#125; access_log /var/log/nginx/a.com_access.log;&#125;server&#123; listen 80; server_name b.com; location / &#123; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://127.0.0.1:2000; &#125; access_log /var/log/nginx/b.com_access.log;&#125; 假如现在在/usr/share/nginx/blog下再部署一个静态网站, 在sites-enabled/default中如下更改: 123456789101112server &#123; listen 8093 default server; # listen [::]:80 default_server ipv6only=on; root /usr/share/nginx/blog; index index.html index.htm; server_name localhost; location / &#123; try_files $uri $uri/ =404; &#125;&#125; 相应的在sudo vim /etc/nginx/conf.d/vhost.conf中加入:12345678910111213server&#123; listen 80; server_name b.com; location / &#123; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://127.0.0.1:8093; &#125; access_log /var/log/nginx/blog_access.log;&#125; 因为我的两个项目都在本机所以proxy_pass用了127.0.0.1,如果你们的项目在其他服务器上可以直接写ip地址。access_log一定要配置对,不然的话会因找不到这个日志路径而无法重启nginx。多个server就可以配置多个。 重启nginx/etc/init.d/nginx restart LNMP配置 安装mysqlsudo apt-get install mysql-serverapt-get isntall mysql-clientsudo apt-get install libmysqlclient-dev sudo netstat -tap | grep mysql(mysql 的socket处于 listen 状态则表示安装成功) 安装nginx和php安装apt源管理工具、添加nginx和php的安装源 123apt-get install python-software-propertiesadd-apt-repository ppa:nginx/stableadd-apt-repository ppa:ondrej/php5 安装php及对mysql的支持apt-get install php5 php5-fpm php5-mysql php-apc php组件apt-get install php5 php-pear php5-mysql php5-fpm php5-dev curl libcurl3 libcurl3-dev php5-curl php5-mcrypt php5-gd php供选择的组件 123456apt-get install php-pear php5-dev php5-curlapt-get install php5-gd php5-intl php5-imagickapt-get install php5-imap php5-mcrypt php5-memcacheapt-get install php5-ming php5-ps php5-pspellapt-get install php5-recode php5-snmp php5-sqliteapt-get install php5-tidy php5-xmlrpc php5-xsl 安装nginxapt-get install nginx 配置phpvim /etc/php5/fpm/php.ini,找到：;cgi.fix_pathinfo=1,改为：cgi.fix_pathinfo=0 配置nginxvim /etc/nginx/sites-enabled/default。最后重启服务：重启相关服务sudo service php5-fpm start(reload); sudo service nginx start(reload)。可使用nginx -t -c /etc/nginx/nginx.conf查看配置情况是否正确。||:解决php-fpm与nginx的小bug按上述步骤操作后，由于nginx与php-fpm之间的一个小bug，会导致这样的现象：网站中的静态页面 .html 都能正常访问，而 .php 文件虽然会返回200状态码，但实际输出给浏览器的页面内容却是空白。简而言之，原因是nginx无法正确的将 *.php 文件的地址传递给php-fpm去解析，相当于php-fpm接受到了请求，但这请求却指向一个不存在的文件，于是返回空结果。为了解决这个问题，需要改动nginx默认的fastcgi_params配置文件：vi /etc/nginx/fastcgi_params在文件的最后增加一行：fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;nginx config page:12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455server &#123; listen 80 default_server; listen [::]:80 default_server; # SSL configuration # # listen 443 ssl default_server; # listen [::]:443 ssl default_server; # # Note: You should disable gzip for SSL traffic. # See: https://bugs.debian.org/773332 # # Read up on ssl_ciphers to ensure a secure configuration. # See: https://bugs.debian.org/765782 # # Self signed certs generated by the ssl-cert package # Don&apos;t use them in a production server! # # include snippets/snakeoil.conf; root /var/www; # Add index.php to the list if you are using PHP index index.php index.html index.htm index.nginx-debian.html; server_name _; location / &#123; # First attempt to serve request as file, then # as directory, then fall back to displaying a 404. try_files $uri $uri/ =404; &#125; # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # location ~ \.php$ &#123; try_files $uri =404; # include snippets/fastcgi-php.conf; # fastcgi_split_path_info ^(.+.\php)(/.+)$; # # # With php5-cgi alone: # fastcgi_pass 127.0.0.1:9000; # # With php5-fpm: fastcgi_pass unix:/var/run/php5-fpm.sock; fastcgi_index index.php; include fastcgi_params; &#125; # deny access to .htaccess files, if Apache&apos;s document root # concurs with nginx&apos;s one # location ~ /\.ht &#123; deny all; &#125;&#125; 环境变量登陆系统时shell读取的顺序应该是:/etc/profile(所有用户的环境变量) -&gt; /etc/enviroment(系统的环境变量) -&gt; $HOME/.profile -&gt; $HOME/.env（1）/etc/profile： 此文件为系统的每个用户设置环境信息,当用户第一次登录时,该文件被执行. 并从/etc/profile.d目录的配置文件中搜集shell的设置。（2）/etc/bashrc: 为每一个运行bash shell的用户执行此文件.当bash shell被打开时,该文件被读取。（3）~/.bash_profile: 每个用户都可使用该文件输入专用于自己使用的shell信息,当用户登录时,该文件仅仅执行一次!默认情况下,他设置一些环境变量,执行用户的.bashrc文件。export PATH=/opt/EmbedSky/4.3.3/bin:$PATH（4）~/.bashrc: 该文件包含专用于你的bash shell的bash信息,当登录时以及每次打开新的shell时,该该文件被读取。（5） ~/.bash_logout:当每次退出系统(退出bash shell)时,执行该文件. 另外,/etc/profile中设定的变量(全局)的可以作用于任何用户,而~/.bashrc等中设定的变量(局部)只能继承 /etc/profile中的变量,他们是”父子”关系。（6）~/.bash_profile 是交互式、login 方式进入 bash 运行的~/.bashrc 是交互式 non-login 方式进入 bash 运行的通常二者设置大致相同，所以通常前者会调用后者。]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JS_AngularJS_jQuery's TRICK]]></title>
    <url>%2F2016%2F11%2F28%2FJS-use-trick%2F</url>
    <content type="text"><![CDATA[内联元素与块级元素区别 block（1）独占一行（2）width\height\padding\margin都可控（3）address\blockquote\center\dir\div\dl\fieldset\form\h\hr\isindex\menu\noframe\noscript\ol\p\pre\table\ul\li inline（1）与相邻内联元素同一行（2）width\height\padding-top\padding-bottom\margin-top\margin-bottom都不可控（3）a\abbr\acronym\b\bdo\big\br\cite\code\dfn\em\font\i\img\input\kbd\label\q\s\samp\select\small\span\strike\strong\sub\sup\textarea\tt\u\var 在CSS中的应用display:block/inline/inline-block(表现为同行显示但是可以修改宽高内外边距) 内联元素中也可以放块级元素，而且内部的块级元素会撑大外部的内联标签。]]></content>
      <categories>
        <category>FRONTEND</category>
      </categories>
      <tags>
        <tag>CSS</tag>
        <tag>JS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RockMongo-PHP MongoDB Administrator-配置(Windows环境)]]></title>
    <url>%2F2016%2F11%2F05%2Farticle-3%2F</url>
    <content type="text"><![CDATA[前期准备RockMongo是PHP5写的一个MongoDB管理工具。 一个能运行PHP的Web服务器，比如Apache ，Httpd, Nginx…我选择的是Apache服务器，具体配置如下： 环境配置下载地址，选择对应平台，下载。下载截图如下所示： 安装与设置解压下载的压缩包，找到readme_first.html文件，里面有详细的安装步骤。找到Apache的配置文件httpd.config打开，修改包括ServerRoot、DocumentRoot、Directory，ScriptAlias等字段，需要改为你的Apache目录的地址。也可以自定义端口号通过listen port字段。为了支持PHP5，还需要添加以下内容：12345# php5 supportLoadModule php5_module path/to/php5apache2_4.dll(即解压的PHP压缩包中的php5apache2_4.dll文件的目录)AddType application/x-httpd-php .php .html .htm# configure the path to php.iniPHPIniDir &quot;your php path&quot; PHP - 需要PHP v5.1.6或更高版本，需要支持SESSION下载PHP(windows下),我选择的是VC11 x64 Thread Safe (2016-Oct-14 20:34:09)，如果与Apache注意选择thread safe版的，否则解压出来没有php5apache2_4.dll文件。而non thread safe主要与IIS搭配环境。为了能连接MongoDB，需要安装php_mongo扩展。下载后将压缩包解压，复制php_mongo.dll文件到PHP文件夹下的ext目录下。解压PHP压缩包，将php的目录路径和php主目录下的ext一起加到环境变量。然后复制php.ini-production文件，重命名为php.ini并打开。将extension=php_mbstring.dll字段前的分号去掉，并加入新的字段extension=php_mongo.dll。extension支持完整路径，所以如果出现php无法加载模块时可以考虑采用完整路径，我的完整路径为extension=c:/php-5.6.27/ext/php_mbstring.dll和extension=c:/php-5.6.27/ext/php_mongo.dll。检查环境： 12345[method1]打开htdocs下的index.html,在结尾处加入&lt;?php phpinfo()?&gt;在浏览器中打开localhost,如果正确输出PHP信息说明PHP+Apache配置完成，如果能找到mongo的支持信息，说明和mongodb的连接也配置完成了，否则需要重新配置与mongo相关的信息。[method2]在命令行输入：php -i | findstr mongo查看mongo的支持信息。 RockMongo不要在官网上下载，否则由于版本问题导致无法启动，到github上下载，然后解压出来放到你的Apache配置文件中的DocumentRoot字段指定的目录，我的是c:\Apache24\htdocs。至此环境搭建完毕。打开MongoDB，在浏览器地址中输入localhost/rockmongo/index.php即可进行登录和管理数据库了。]]></content>
      <categories>
        <category>BACKEND</category>
      </categories>
      <tags>
        <tag>rockmongo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GitHub + Hexo搭建个人博客总结]]></title>
    <url>%2F2016%2F10%2F20%2Farticle-2%2F</url>
    <content type="text"><![CDATA[前期准备 连接远程库 用Hexo创建博客框架 Hexo安装 Hexo部署 将本地文件部署到 GitHub 将本地文件部署到阿里云 写博客 第三方主题 任意门 前期准备 GitHub账号。并新建repository。与GitHub建立好连接之后，就可以方便的使用它提供的 Pages 服务，GitHubPages分两种，一种是用你的GitHub用户名建立的username.github.io这样的用户&amp;组织站点，另一种是依附项目的Pages。想建立个人博客是用的第一种，形如username.github.io这样的可访问的站点。参照此教程。 软件环境 Node.js Git for Windows 连接远程库 检查SSH keys的设置首先我们需要检查你电脑上现有的ssh key： 12$ cd ~/.sh(如果显示如果显示“No such file or directory”，跳到第三步，否则继续。) 备份和移除原来的ssh key设置因为已经存在key文件，所以需要备份旧的数据并删除： 1234$ ls$ mkdir key_backup$ cp id_rsa* key_backup$ rm id_rsa* 生成新的SSH Key输入下面的代码，就可以生成新的key文件，我们只需要默认设置就好，所以当需要输入文件名的时候，回车就好。 123$ ssh-keygen -t rsa -C "邮件地址@youremail.com"Generating public/private rsa key pair.Enter file in which to save the key (/Users/your_user_directory/.ssh/id_rsa):&lt;回车就好or自定义路径&gt; 然后系统会要你输入加密串（Passphrase）&lt;可以直接Enter&gt;。 添加SSH Key到GitHub用文本编辑工具打开id_rsa.pub文件，如果看不到这个文件，你需要设置显示隐藏文件。准确的复制这个文件的内容，才能保证设置的成功。在GitHub的主页上点击设置按钮。选择SSH Keys项，把复制的内容粘贴进去，然后点击Add Key按钮即可。PS：如果需要配置多个GitHub账号，可以搜索 多个github帐号的SSH key切换的方法。 建立连接我们如何让本地git项目与远程的GitHub建立联系呢？用SSH key。在桌面或开始菜单中找到 Git Shell，打开后输入以下命令： 123456$ ssh -T git@github.com(如果是下面之类的反馈（或者显示 Hi xxx）：The authenticity of host 'github.com (207.97.227.239)' can\'t be established. RSA key fingerprint is 16:27:ac:a5:76:28:2d:36:63:1b:56:4d:eb:df:a6:48. Are you sure you want to continue connecting (yes/no)?输入`yes`即可。) 设置你的账号信息(可选)现在你已经可以通过SSH链接到GitHub了，还有一些个人信息需要完善的。Git会根据用户的名字和邮箱来记录提交。GitHub也是用这些信息来做权限的处理，输入下面的代码进行个人信息的设置，把名称和邮箱替换成你自己的，名字必须是你的真名，而不是GitHub的昵称。 12$ git config --global user.name "你的名字"$ git config --global user.email "your_email@youremail.com" 用Hexo创建博客框架Hexo安装（在Git Bash中操作）123$ cd ~/your_path/$ npm install hexo-cli -g(如果速度慢可以在后面加入`--registry=http://registry.npm.taobao.org`淘宝源) Hexo部署（在Git Bash中操作）Hexo的部署可采用如下方法，输入命令： hexo init [文件名]。12$ cd ~/your_path/$ hexo init your_profilename 然后cd到your_profilename中，再输入以下命令，安装依赖文件：12$ cd your_profilename$ npm install 部署成功之后，Hexo 会自动在目标文件夹建立博客网站所需要的所有文件。此时可以通过输入以下命令在本地进行预览（在刚才创建的文件夹里）：12$ hexo generate$ hexo server 此时打开浏览器，在浏览器地址栏输入 http://localhost:4000/ （默认端口为4000）, 便可以看到最原始的博客了。 将本地文件部署到 GitHub 修改 Hexo 文件中的 _config.yml 文件找到其中的 deploy 标签，改成下图所示形式，并保存。注意：冒号后面要加上一个空格，否则会报错。 将其 deploy 到仓库中（在Git Bash中操作）123$ hexo clean$ hexo generate$ hexo deploy 如果出现下图错误:将_config.yml中的 deploy 标签的 type 改成 git，然后再在 Git Shell 中运行以下命令:1$ npm install hexo-deployer-git --save 之后重复第二步中的命令即可。到这一步，个人博客就已经部署到 GitHub 上了，你可以到你的GitHub仓库查看是否已经更新。此时,通过 your_user_name.github.io（即你那个仓库的名称，形如：”你的 GitHub 用户名”.github.io）,就可以看到你的个人博客了。 将本地文件部署到阿里云1git clone blog.git 写博客具体操作可以参考官方文档快捷命令：123456$ hexo g == hexo generate$ hexo d == hexo deploy$ hexo s == hexo server$ hexo n == hexo new# 还能组合使用，如：$ hexo d -g 安装第三方主题 使用Hexo生成的博客使用的是Hexo的默认主题：Landscape。可以采用其他主题。本博客采用的NexT主题。 NexT主题安装参看其文档。 本文参考了这边篇博文和自己的搭建经历总结而成，有疑问处自行Google之。 任意门 jekyll]]></content>
      <categories>
        <category>FRONTEND</category>
      </categories>
      <tags>
        <tag>博客搭建 Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何评价电影《言叶之庭》？]]></title>
    <url>%2F2016%2F10%2F19%2Farticle%2F</url>
    <content type="text"><![CDATA[剧透！慎入！！！很典型的新海诚风格，细腻绵密，朦胧幽远的感情描写。所有的情愫好似蒙着薄纱，无论喜悦祥和，还是忧愁苦闷，都显得不清晰，不言说，似喜非喜，似愁非愁。但这种情感的压抑（无论来自外界还是内心）并不是如爇热炎夏滂沱欲来时的沉闷躁动，却如冬日午后孤身一人有所思念，欲与人诉而万籁俱静时的无奈与释然。 如果说《秒5》是同一个世界的两个人如何远去为两个世界，那么《言叶之庭》就是两个世界的人（就年龄相差一轮，身份为师生之别而言）如何走到同一个世界，然后再。。。 故事在15岁的孤寂的秋月和27岁的同样孤寂的雪野庭院区域相逢的情节下展开，相逢地点值得一提的是位于繁华喧嚣的林立高楼包围中的庭院区域，雨季中，这个公园就犹如桃花源，美得清新淡漠甚而有些梦幻心酸。而这雨中的美丽的庭院就像两人的心一样也是孤独的（后来有一对情侣说没想公园到这么大，可以看出平时很少人，即使有也没有真正欣赏的），而雨中的庭院却是他们各自世界的交集，一个当他们“走不下去”时的落脚地。在这个公园中，留在自己世界（做鞋子）里的秋月发现了令他动心的雪野的“神秘世界”，于是两颗心在一次次的雨中相互靠近湿润融合。这种融合是否建立在坚固基础上？从剧中推测，秋月成长经历应该是孤独无依（精神上），尽管他有父母和哥哥，有过一段快乐经历（小时候，母亲过生日，父子三人送给妈妈一双鞋，叫着：哥哥，等等我。），但之后他的父亲没有出现过，步入高中的秋月在“上学家务打工”中经历着一天又一天。他母亲在家也和哥哥吵架，最后和一个也小她一轮的男友离家出走了，但未必是幸福的（哥哥说：吵完架会回来可以看出）。这种情况下，秋月却有着一个设计制造鞋子的“不现实的”梦想，这一点不知是否与送鞋子给妈妈当生日礼物的情节有关，觉得那个时候是幸福的，想通过制鞋来弥补心理上的苦闷与期许（和雪野聊天时，毫不犹豫说出做女鞋，我觉得秋月下意时想到的是他妈妈，虽然最后是给雪野做的）。同时鞋子的功用是辅助行走的，秋月做鞋子，寓意他想靠自己力量走的“更稳健”。但从另一个角度，鞋子在保护脚行走的同时，无形中也是一种对脚的“束缚”（寓意着某种社会规则或者某种不可抗拒的命理趋势，比如：女主最后光着脚从房间冲出来时，给了几双鞋子一个特写，与其说是女主急迫毋宁说女主勇敢的无视了“那些鞋子”寓意的东西），我们的行走离不开这种束缚，而行走的目的却是为了挣脱，这是一种惨烈的怪圈。 还有一点是：男主是否有俄狄浦斯情结（小人之心猜度）？ 雪野一个美得让人心碎的女子，一个艰难行走着的善良的人，她也是孤独的，她说：虽然27岁了，但并不比15岁是聪明，一直在原地踏步，以至于因为和学生的矛盾导致不愿去学校上课而走不下去（秋月为这事打了学姐一耳光，妙就妙在，当他向雪野讲述时表现的是自我调侃的释然，），由于流言蜚语，她的男友也离他远去（雪野说他只收集周围的声音，而不听她的只言片语，看来她男友也不是真正理解她的人），这也导致了雪野的味觉障碍，后来与秋月相识后有所改善。 不论是秋月还是雪野都在艰难的前行，孤独的前行，而且前行的不顺利也不稳健（内在的心智的不成熟，外界的无形的命运的不可抗拒的不可掌控的力量）。 虽然最后他们都向前迈出了一步，将内心的情感表达出来了，但雪野还是回到了四国岛（学会自己走下去），秋月继续着梦想，继续去着言叶之庭，当看到雪野的信（为什么不是手机之类通讯方式）后，决定自己走的更稳健时再去见雪野，可能雪野也是这样想的。这一幕让我想起了《秒5》里男主吻了女主后说一切都变了。或许当走的更稳健后，一切都变了。所以作者留给我们的是一个易碎美梦，结果是秋月穿着自己做的鞋离雪野越来越远。 秋月当空，苍茫雪野，相逢无期。或许在某个雨天。。。隐约雷鸣，阴霾天空，即使天无雨，我亦留此地。]]></content>
      <categories>
        <category>影评</category>
      </categories>
      <tags>
        <tag>影像</tag>
        <tag>评论</tag>
      </tags>
  </entry>
</search>
